{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4209d50-91f0-432d-aab8-501185351398",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf9ad7-6aba-4d85-ace4-43cfebf46733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from llama.data_pipeline import tiny_shakespeare, dataset\n",
    "from llama.model.tokenizer import CharacterTokenizer\n",
    "from llama.model.custom_layers import *\n",
    "from llama.model.custom_blocks import *\n",
    "from llama.model import model, training\n",
    "from llama.constants import *\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38ff6c-4b30-4718-bfbb-5d9b99f414f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration object for model parameters\n",
    "CONFIG = {\n",
    "    'vocab_size': -1,        # TBD based on dataset\n",
    "    'batch_size': 64,        # Number of batches to be processed at each random split\n",
    "    'epochs': 3,             # Number of training epochs\n",
    "    'context_window': 16,    # Number of characters in each input (x) and target (y) sequence of each batch\n",
    "    'd_model': 128,          # Dimension of linear layers (128)\n",
    "    'n_heads': 8,            # number of attention heads\n",
    "    'n_layers': 4,           # Set the number of layers to 4\n",
    "}\n",
    "\n",
    "experiment_dir = os.path.join(EXPERIMENTS_DIR, 'chartokenizer_llama_shakespeare')\n",
    "os.makedirs(experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16571b-4c0e-41eb-9434-7d7f90be7629",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca2d41-6cb3-475a-a2f0-d375724d5088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stores the tiny shakespeare dataset to disk\n",
    "data_path = tiny_shakespeare.download_tiny_shakespeare()\n",
    "\n",
    "# Read the content of the dataset\n",
    "with open(data_path, 'r') as f:\n",
    "    lines = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29978af-66c7-4137-9c27-4aa4a8554295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sorted list of unique characters in the dataset\n",
    "character_counts = Counter(lines)\n",
    "vocab = sorted(list(set(lines)))\n",
    "print(character_counts)\n",
    "\n",
    "# update the vocabulary size in the configuration\n",
    "CONFIG['vocab_size'] = len(vocab)\n",
    "\n",
    "# Output the total number of characters in our dataset (Vocabulary Size)\n",
    "print(f'Total number of characters in our dataset (Vocabulary Size): {CONFIG[\"vocab_size\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6efab58-c0cc-40d4-8a02-892aa2c4803a",
   "metadata": {},
   "source": [
    "# Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba11f4-ca55-4eb6-9de3-ecd281292167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = CharacterTokenizer(vocab)\n",
    "\n",
    "# check encode and decode functions\n",
    "tokenizer.decode(tokenizer.encode(\"hello world!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea2ca9-ce7b-42dc-8077-2476a323ed32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the text data\n",
    "train_split = lines[:int(0.8 * len(lines))]\n",
    "val_split = lines[int(0.8 * len(lines)): int(0.9 * len(lines))]\n",
    "test_split = lines[int(0.9 * len(lines)):]\n",
    "\n",
    "# create a dataset for each split\n",
    "train_dataset = dataset.TextDataset([train_split], tokenizer, CONFIG['context_window'], device)\n",
    "val_dataset = dataset.TextDataset([val_split], tokenizer, CONFIG['context_window'], device)\n",
    "test_dataset = dataset.TextDataset([test_split], tokenizer, CONFIG['context_window'], device)\n",
    "\n",
    "# create a dataloader for each split\n",
    "bs = CONFIG['batch_size']\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "print(f\"Steps train: {len(train_dataloader)}, val: {len(val_dataloader)}, test: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205446e-fc34-43aa-9b4d-19f05ee1a6a9",
   "metadata": {},
   "source": [
    "# Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fa723-8a15-48df-a29b-b00e66acefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Llama model\n",
    "llama = model.Llama(CONFIG)\n",
    "llama = llama.to(device)\n",
    "print(f\"Model params: {sum([p.numel() for p in llama.parameters()]):,}\")\n",
    "\n",
    "# create the corresponding optimizer\n",
    "optimizer = torch.optim.Adam(llama.parameters(), lr=1e-3)\n",
    "\n",
    "# create a step learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847a618-7271-40bc-b0ed-990aab14796d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_losses = training.train(llama, optimizer, train_dataloader, val_dataloader, CONFIG['epochs'], lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2927908-faa5-4a64-8a4b-ce4fbbe64f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "df_losses[['train', 'val']].plot(ax=ax1)\n",
    "df_losses[['lr']].plot(ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85678d8-bdf8-4adc-ad1c-d55e5714d371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# check loss on test split\n",
    "training.evaluate_loss(llama, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c861d3-d62e-44ff-b2be-fd9a661680fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate text using the trained LLM (llama) with a maximum of 500 tokens\n",
    "generated_text = llama.generate(device, tokenizer, 500)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef857b-3831-4938-ae53-5f8d99d8e649",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7dad92-24f7-4cd7-89d1-a495108da563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the entire model\n",
    "torch.save(llama, os.path.join(experiment_dir, 'llama.pth'))\n",
    "\n",
    "# save only the model parameters\n",
    "# torch.save(llama.state_dict(), os.path.join(experiment_dir, 'llama_model_parameters.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b364360-c4f6-4d22-897b-79dc862bc00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check loaded model\n",
    "llama_loaded = torch.load(os.path.join(experiment_dir, 'llama.pth'))\n",
    "\n",
    "print(llama_loaded.generate(device, tokenizer, max_new_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c1b95-0498-4cb2-93a9-dfbddb68bbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44776c9-52fc-40b6-b6dd-7a0fd59e72b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
