{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "from blazeface.dataset import input_dataset, anchors, target_encoder, prediction_decoder, utils\n",
    "from blazeface.model import losses\n",
    "from blazeface.constants import N_LANDMARKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-fortune",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take small subset of the training set to analyze\n",
    "data_train, info = input_dataset.load_the300w_lp(split=\"train[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data_train.take(1):\n",
    "    break\n",
    "\n",
    "print(x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-manual",
   "metadata": {},
   "source": [
    "# Visualize raw labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmarks(sample, ax, landmarks=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample (dict): must contain keys 'image' and 'landmarks_2d'.\n",
    "        ax (AxesSubplot):\n",
    "        landmarks (np.ndarray): if given, it will override 'landmarks_2d' in sample.\n",
    "    \"\"\"\n",
    "    img = sample['image']\n",
    "    if landmarks is None:\n",
    "        landmarks = sample['landmarks_2d'].numpy()\n",
    "    shape = tf.shape(img).numpy()\n",
    "    ax.scatter(landmarks[:,0] * shape[0], landmarks[:,1] * shape[1], alpha=0.6, s=2, c='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i, x in enumerate(data_train.take(n_rows * n_cols)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x['image'])\n",
    "    visualize_landmarks(x, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-three",
   "metadata": {},
   "source": [
    "# Visualize preprocessed data (inputs to BlazeFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(sample, ax):\n",
    "    img = sample['image']\n",
    "    shape = tf.shape(img).numpy()\n",
    "    x1, y1, x2, y2 = input_dataset.landmarks_to_bboxes(x['landmarks_2d']).numpy()\n",
    "    x1 *= shape[1]\n",
    "    y1 *= shape[0]\n",
    "    x2 *= shape[1]\n",
    "    y2 *= shape[0]\n",
    "    rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec='green')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i, x in enumerate(data_train.take(n_rows * n_cols)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x['image'])\n",
    "    # visualize bbox\n",
    "    visualize_bbox(x, ax)\n",
    "    # visualize landmarks\n",
    "    landmarks_2d = input_dataset.reduce_landmarks(x['landmarks_2d']).numpy()\n",
    "    visualize_landmarks(x, ax, landmarks=landmarks_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-wallace",
   "metadata": {},
   "source": [
    "# Visualize anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anchors = anchors.generate_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for i, loc in enumerate(all_anchors):\n",
    "    x1, y1, w, h = loc\n",
    "    c = mcolors.CSS4_COLORS[list(mcolors.CSS4_COLORS.keys())[int(i % len(mcolors.CSS4_COLORS.keys()))]]\n",
    "    rect = Rectangle((x1 - w/2, y1-h/2), w, h, fc=\"None\", ec=c, alpha=0.9, lw=0.5)\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-moore",
   "metadata": {},
   "source": [
    "# Create input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_train\n",
    "ds = ds.map(input_dataset.unpack_dct)\n",
    "ds = ds.map(input_dataset.preprocess_image_and_pass_landmarks)\n",
    "ds = ds.map(lambda img, lmarks: (img, input_dataset.landmarks_to_bboxes(lmarks), input_dataset.reduce_landmarks(lmarks)))\n",
    "\n",
    "ds = ds.batch(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-ceramic",
   "metadata": {},
   "source": [
    "# Visualize bounding boxes and landmark coordinate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = []\n",
    "lmarks = []\n",
    "for sample_batch in ds.take(1000):\n",
    "    bboxes += sample_batch[1].numpy().tolist()\n",
    "    lmarks += sample_batch[2].numpy().tolist()\n",
    "\n",
    "bboxes = np.array(bboxes)\n",
    "lmarks = np.array(lmarks)\n",
    "\n",
    "bboxes = np.squeeze(bboxes)\n",
    "lmarks = np.squeeze(lmarks)\n",
    "\n",
    "bboxes.shape, lmarks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.set_title(\"BBox Coordinate Distributions\", fontsize=16)\n",
    "sns.kdeplot(x=bboxes[:,0], y=bboxes[:,1], cmap='coolwarm', fill=True, thresh=0.01, ax=ax)\n",
    "sns.kdeplot(x=bboxes[:,2], y=bboxes[:,3], cmap='coolwarm', fill=True, thresh=0.01, ax=ax)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('bbox x', fontsize=13)\n",
    "ax.set_ylabel('bbox y', fontsize=13)\n",
    "ax.invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.set_title(\"Landmark Coordinate Distributions\", fontsize=16)\n",
    "\n",
    "sns.kdeplot(x=np.reshape(lmarks, (-1, 2))[:, 0], y=np.reshape(lmarks, (-1, 2))[:, 1], cmap='coolwarm', fill=True, thresh=0.01, ax=ax)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('landmark x', fontsize=13)\n",
    "ax.set_ylabel('landmark y', fontsize=13)\n",
    "ax.invert_yaxis();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-aside",
   "metadata": {},
   "source": [
    "# Visualize positive anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(lambda img, bboxes, lmarks: (img, target_encoder.calculate_targets(all_anchors, bboxes, lmarks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_batch in ds.take(1):\n",
    "    break\n",
    "\n",
    "deltas = sample_batch[1]['deltas']\n",
    "labels = sample_batch[1]['labels']\n",
    "\n",
    "sample_batch[0].shape, [e.shape for e in sample_batch[1].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 3\n",
    "n_cols = 4\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4 * n_rows))\n",
    "colors = dict(zip(range(len(mcolors.CSS4_COLORS)), mcolors.CSS4_COLORS.values()))\n",
    "\n",
    "def scale_coordinates(img, x1, y1, x2, y2):\n",
    "    x1 *= img.shape[1]\n",
    "    y1 *= img.shape[0]\n",
    "    x2 *= img.shape[1]\n",
    "    y2 *= img.shape[0]\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "for i, ax in enumerate(np.ravel(axes)):\n",
    "    img = sample_batch[0][i]\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for ci, pos_anchor in enumerate(all_anchors[tf.cast(labels[i, :, 0], dtype=tf.bool)]):\n",
    "        x1, y1, x2, y2 = utils.xywh_to_xyxy(pos_anchor)\n",
    "        x1, y1, x2, y2 = scale_coordinates(img, x1, y1, x2, y2)\n",
    "        rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec=colors[5*ci])\n",
    "        ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-incidence",
   "metadata": {},
   "source": [
    "# Apply decoder and test loss calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = prediction_decoder.get_bboxes_and_landmarks_from_deltas(all_anchors, deltas)\n",
    "\n",
    "dec[0][np.reshape(labels, (12, 896))[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss = losses.RegressionLoss()\n",
    "reg_loss(deltas, deltas + tf.random.normal(deltas.shape, 0, 0.5, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_loss = losses.ClassLoss()\n",
    "class_loss(labels, tf.cast(tf.random.uniform(labels.shape, 0, 1, dtype=tf.float32), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-christian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-toner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blazeface",
   "language": "python",
   "name": "blazeface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
