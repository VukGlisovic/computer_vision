{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from blazeface.dataset import input_dataset, anchors, target_encoder, prediction_decoder, utils\n",
    "from blazeface.model import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-emergency",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take small subset of the training set to analyze\n",
    "data_train, info = input_dataset.load_the300w_lp(split=\"train[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data_train.take(1):\n",
    "    break\n",
    "\n",
    "print(x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-design",
   "metadata": {},
   "source": [
    "# Visualize raw labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmarks(sample, ax, landmarks=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sample (dict): must contain keys 'image' and 'landmarks_2d'.\n",
    "        ax (AxesSubplot):\n",
    "        landmarks (np.ndarray): if given, it will override 'landmarks_2d' in sample.\n",
    "    \"\"\"\n",
    "    img = sample['image']\n",
    "    if landmarks is None:\n",
    "        landmarks = sample['landmarks_2d'].numpy()\n",
    "    shape = tf.shape(img).numpy()\n",
    "    ax.scatter(landmarks[:,0] * shape[0], landmarks[:,1] * shape[1], alpha=0.6, s=2, c='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i, x in enumerate(data_train.take(n_rows * n_cols)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x['image'])\n",
    "    visualize_landmarks(x, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-shareware",
   "metadata": {},
   "source": [
    "# Visualize preprocessed data (inputs to BlazeFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(sample, ax):\n",
    "    img = sample['image']\n",
    "    shape = tf.shape(img).numpy()\n",
    "    x1, y1, x2, y2 = input_dataset.landmarks_to_bboxes(x['landmarks_2d']).numpy()\n",
    "    x1 *= shape[1]\n",
    "    y1 *= shape[0]\n",
    "    x2 *= shape[1]\n",
    "    y2 *= shape[0]\n",
    "    rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec='green')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5\n",
    "n_cols = 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i, x in enumerate(data_train.take(n_rows * n_cols)):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x['image'])\n",
    "    # visualize bbox\n",
    "    visualize_bbox(x, ax)\n",
    "    # visualize landmarks\n",
    "    landmarks_2d = input_dataset.reduce_landmarks(x['landmarks_2d']).numpy()\n",
    "    visualize_landmarks(x, ax, landmarks=landmarks_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-observation",
   "metadata": {},
   "source": [
    "# Visualize anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_anchors = anchors.generate_anchors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for i, loc in enumerate(all_anchors):\n",
    "    y1, x1, w, h = loc\n",
    "    c = mcolors.CSS4_COLORS[list(mcolors.CSS4_COLORS.keys())[int(i % len(mcolors.CSS4_COLORS.keys()))]]\n",
    "    rect = Rectangle((x1 - w/2, y1-h/2), w, h, fc=\"None\", ec=c, alpha=0.9, lw=0.5)\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-navigator",
   "metadata": {},
   "source": [
    "# Create input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = data_train\n",
    "ds = ds.map(input_dataset.unpack_dct)\n",
    "ds = ds.map(input_dataset.preprocess_image)\n",
    "ds = ds.map(lambda img, lmarks: (img, input_dataset.landmarks_to_bboxes(lmarks), input_dataset.reduce_landmarks(lmarks)))\n",
    "\n",
    "ds = ds.batch(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_batch in ds.take(1):\n",
    "    break\n",
    "\n",
    "[element.shape for element in sample_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas, labels = target_encoder.calculate_targets(all_anchors, sample_batch[1], sample_batch[2])\n",
    "\n",
    "deltas = deltas.numpy()\n",
    "labels = labels.numpy()\n",
    "deltas.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = prediction_decoder.get_bboxes_and_landmarks_from_deltas(all_anchors, deltas)\n",
    "dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec[0][np.reshape(labels, (8, 896))[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-nurse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "colors = dict(zip(range(len(mcolors.CSS4_COLORS)), mcolors.CSS4_COLORS.values()))\n",
    "\n",
    "i = 5\n",
    "img = sample_batch[0][i]\n",
    "bbox = sample_batch[1][i]\n",
    "ax.imshow(img)\n",
    "\n",
    "x1, y1, x2, y2 = bbox[0]\n",
    "x1 *= img.shape[1]\n",
    "y1 *= img.shape[0]\n",
    "x2 *= img.shape[1]\n",
    "y2 *= img.shape[0]\n",
    "rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec='green', lw=3)\n",
    "ax.add_patch(rect)\n",
    "\n",
    "\n",
    "for ci, pos_anchor in enumerate(all_anchors[tf.cast(labels[i, :, 0], dtype=tf.bool)]):\n",
    "    x1, y1, x2, y2 = utils.xywh_to_xyxy(pos_anchor)\n",
    "    x1 *= img.shape[1]\n",
    "    y1 *= img.shape[0]\n",
    "    x2 *= img.shape[1]\n",
    "    y2 *= img.shape[0]\n",
    "    rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec=colors[5*ci])\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_loss = losses.ClassLoss()\n",
    "reg_loss = losses.RegressionLoss()\n",
    "\n",
    "reg_loss(deltas, deltas + tf.random.normal(deltas.shape, 0, 0.5, dtype=tf.float32))\n",
    "\n",
    "class_loss(labels, tf.cast(tf.random.uniform(labels.shape, 0, 1, dtype=tf.float32), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blazeface",
   "language": "python",
   "name": "blazeface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
