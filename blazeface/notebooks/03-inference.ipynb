{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from blazeface.constants import *\n",
    "from blazeface.dataset import input_dataset, anchors, target_encoder, prediction_decoder, utils\n",
    "from blazeface.model import blazeface, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-hydrogen",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, all_anchors = blazeface.load_model('../data/experiments/20221031_run000/checkpoints/weights-16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-reservation",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take small subset of the training set to analyze\n",
    "data_validation, info = input_dataset.load_the300w_lp(split=\"train[10%:]\")\n",
    "\n",
    "ds_validation = input_dataset.create_images_dataset(data_validation, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-merchandise",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds_validation.take(5): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_coordinates = prediction_decoder.get_bboxes_and_landmarks_from_deltas(all_anchors, predictions['deltas'])\n",
    "\n",
    "predictions['labels'].shape, pred_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = tf.cast(predictions['labels'], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_suppressed_data = prediction_decoder.weighted_suppression(pred_scores[0], pred_coordinates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_bboxes = weighted_suppressed_data[..., 0:4]\n",
    "weighted_landmarks = weighted_suppressed_data[..., 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "denormalized_bboxes = utils.denormalize_bboxes(weighted_bboxes, IMG_SIZE, IMG_SIZE)\n",
    "weighted_landmarks = tf.reshape(weighted_landmarks, (-1, N_LANDMARKS, 2))\n",
    "denormalized_landmarks = utils.denormalize_landmarks(weighted_landmarks, IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "ax.imshow(x[0])\n",
    "\n",
    "for index, bbox in enumerate(denormalized_bboxes):\n",
    "    x1, y1, x2, y2 = tf.split(bbox, 4)\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    if width <= 0 or height <= 0:\n",
    "        continue\n",
    "    rect = Rectangle((x1, y1), width, height, fc=\"None\", ec='green', lw=2, alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "for index, landmark in enumerate(denormalized_landmarks):\n",
    "    if tf.reduce_max(landmark) <= 0:\n",
    "        continue\n",
    "    ax.scatter(landmark[:, 0], landmark[:, 1], alpha=0.9, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-trader",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pred_coordinates[predictions['labels'][:, :, 0] > 0.9]\n",
    "temp_bboxes = temp[..., 0:4]\n",
    "temp_lmarks = temp[..., 4:]\n",
    "temp_lmarks = tf.reshape(temp_lmarks, (-1, N_LANDMARKS, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x[0])\n",
    "ax.scatter(utils.denormalize_landmarks(temp_lmarks, 128, 128)[0, :, 0], utils.denormalize_landmarks(temp_lmarks, 128, 128)[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x[1])\n",
    "ax.scatter(utils.denormalize_landmarks(temp_lmarks, 128, 128)[0, :, 0], utils.denormalize_landmarks(temp_lmarks, 128, 128)[0, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(temp[0, 4::2], temp[0, 5::2])\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-trash",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-original",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_suppressed_data = prediction_decoder.weighted_suppression(predictions['labels'][0], pred_coordinates[0])\n",
    "\n",
    "weighted_bboxes = weighted_suppressed_data[..., 0:4]\n",
    "weighted_landmarks = weighted_suppressed_data[..., 4:]\n",
    "\n",
    "denormalized_bboxes = utils.denormalize_bboxes(weighted_bboxes, x.shape[2], x.shape[1])\n",
    "weighted_landmarks = tf.reshape(weighted_landmarks, (-1, N_LANDMARKS, 2))\n",
    "denormalized_landmarks = utils.denormalize_landmarks(weighted_landmarks, x.shape[2], x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 3\n",
    "n_cols = 3\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 15))\n",
    "axes = np.ravel(axes)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x[i])\n",
    "    \n",
    "    weighted_suppressed_data = prediction_decoder.weighted_suppression(predictions['labels'][i], pred_coordinates[i])\n",
    "    weighted_bboxes = weighted_suppressed_data[..., 0:4]\n",
    "    weighted_landmarks = weighted_suppressed_data[..., 4:]\n",
    "    denormalized_bboxes = utils.denormalize_bboxes(weighted_bboxes, x.shape[2], x.shape[1])\n",
    "    weighted_landmarks = tf.reshape(weighted_landmarks, (-1, N_LANDMARKS, 2))\n",
    "    denormalized_landmarks = utils.denormalize_landmarks(weighted_landmarks, x.shape[2], x.shape[1])\n",
    "    x1, y1, x2, y2 = denormalized_bboxes[0]\n",
    "#     print(denormalized_bboxes[0])\n",
    "#     print(denormalized_landmarks[0])\n",
    "    \n",
    "    rect = Rectangle((x1, y1), x2 - x1, y2 - y1, fc=\"None\", ec='green', lw=2)\n",
    "    ax.add_patch(rect)\n",
    "    ax.scatter(denormalized_landmarks[:,0], denormalized_landmarks[:,1], alpha=0.6, s=3, c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-psychology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-transport",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blazeface",
   "language": "python",
   "name": "blazeface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
