{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701169b-54c2-46bb-b5bb-c2c9fcd5eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611981a-2475-4f40-80d9-cc4f73434db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0f9b4-6f3d-4732-93ee-752f78a58ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(\"Hello world! What a [MASK] day it is!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd75eb-9a6f-4e14-93bc-f50bcbf28f1d",
   "metadata": {},
   "source": [
    "# Extracting features for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd494889-aeb3-4c6d-8974-c74962d0a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from datasets import load_dataset_builder, load_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b4bfb-01e2-4e27-a0a9-d84274754bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415fd907-d7b3-4dd1-a04e-cd08f092090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_builder = load_dataset_builder(\"rotten_tomatoes\")\n",
    "print(ds_builder.info.description)\n",
    "print(ds_builder.info.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64feed-ce56-4a98-b789-652ff08d85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = load_dataset(\"rotten_tomatoes\", split=\"train\")\n",
    "ds_validation = load_dataset(\"rotten_tomatoes\", split=\"validation\")\n",
    "ds_test = load_dataset(\"rotten_tomatoes\", split=\"test\")\n",
    "\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03e640-2f70-4626-9237-96744bb665bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_chars = [len(dct['text']) for dct in ds_train]\n",
    "nr_words = [len(dct['text'].split(' ')) for dct in ds_train]\n",
    "\n",
    "print(\"Number of character quantiles\", np.quantile(nr_chars, np.linspace(0, 1, 11)))\n",
    "print(\"Number of words quantiles\", np.quantile(nr_words, np.linspace(0, 1, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b48f30-56c6-43e2-992a-1cf3b615443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for i in tqdm(range(ds_train.num_rows)):\n",
    "    tokens = tokenizer(ds_train[i]['text'], return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    x_train.append(output.pooler_output)\n",
    "x_train = torch.cat(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34962fb3-c60f-4a1e-9000-48fcb6481d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [dct['label'] for dct in ds_train]\n",
    "y_train = torch.tensor(y_train) \\\n",
    "    .reshape((-1, 1)) \\\n",
    "    .float() \\\n",
    "    .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb208bea-4b2d-4dcb-ad9d-f9fa98e1581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163cb1e-470f-48f8-a62d-66d5ea98d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with two dense layers\n",
    "class SimpleNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Parameters for the model and training\n",
    "input_size = x_train.shape[1]  # Size of the input features\n",
    "hidden_size = 128  # Number of units in the hidden layer\n",
    "output_size = 1  # Size of the output (e.g., number of classes in classification)\n",
    "batch_size = 32  # Training batch size\n",
    "\n",
    "# Create the model\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90fa22-57b0-46f4-9e8a-cb2f6227eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7ec35-830c-4438-8514-047718aad1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = [], []\n",
    "for inputs, targets in dataloader:\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    preds.append(outputs)\n",
    "    labels.append(targets)\n",
    "preds = torch.cat(preds)\n",
    "labels = torch.cat(labels)\n",
    "\n",
    "# baseline loss\n",
    "print(\"Loss:\", criterion(preds, labels))\n",
    "print(\"Accuracy\", ((preds > 0.5) == labels).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87a18c-2045-467a-b6ac-d5fa47b63f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911c5ad-a620-408f-ace6-6cb2708dafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (simplified)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = []\n",
    "    for inputs, targets in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss.append(loss.item())\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_loss = np.mean(avg_loss)\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], lr {scheduler.get_last_lr()[0]}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ff08a-0a8c-403f-ac73-157d1c95b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf3131a-f8eb-4ffb-9afb-9366ece9fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464742c5-440a-4a09-9829-b07a3f74cbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a1353-c168-43b4-8eb8-67dd49e07d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = [], []\n",
    "for inputs, targets in dataloader:\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    preds.append(outputs)\n",
    "    labels.append(targets)\n",
    "preds = torch.cat(preds)\n",
    "labels = torch.cat(labels)\n",
    "\n",
    "# baseline loss\n",
    "print(\"Loss:\", criterion(preds, labels))\n",
    "print(\"Accuracy\", ((preds > 0.5) == labels).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814af87-db02-4e65-9eb2-de450e1b4b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-pt",
   "language": "python",
   "name": "huggingface-pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
