{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from yolo.constants import *\n",
    "\n",
    "keras_yolo = importlib.import_module('yolo.vendor.keras-yolo3.yolo3_one_file_to_detect_them_all')\n",
    "bbox = importlib.import_module('yolo.vendor.keras-yolo3.utils.bbox')\n",
    "utils = importlib.import_module('yolo.vendor.keras-yolo3.utils.utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and photo\n",
    "photo_path = os.path.join(DIR_DATA, 'images/traffic.jpg')\n",
    "model_path = os.path.join(DIR_MODELS, 'MSCOCO/model_yolov3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model\n",
    "model = load_model(model_path)\n",
    "# define the expected input shape for the model\n",
    "INPUT_W, INPUT_H = 416, 416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image to detect bounding boxes for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_pixels(filename, shape):\n",
    "    \"\"\"Loads an image, reshapes to the expected input shape\n",
    "    and normalizes the pixel values.\n",
    "    \"\"\"\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = np.expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_path, (INPUT_W, INPUT_H))\n",
    "# make prediction\n",
    "yhat = model.predict(image)\n",
    "# summarize the shape of the list of arrays\n",
    "print([a.shape for a in yhat])\n",
    "\n",
    "# show the rescaled image\n",
    "plt.imshow(image[0,...]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logic to decode the YOLO model output and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    \"\"\"Filters boxes based on their scores. If the score for a particular\n",
    "    box and class is lower than thresh, then drop the box. Otherwise keep\n",
    "    it.\n",
    "    \"\"\"\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(MSCOCO_LABELS)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(MSCOCO_LABELS[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores\n",
    "\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    \"\"\"Translates the predicted bounding boxes back to the original\n",
    "    image size.\n",
    "    \"\"\"\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "\n",
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    \"\"\"Shows the image and plots the bounding boxes.\n",
    "    \"\"\"\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    h, w, _ = data.shape\n",
    "    fig_w = 20\n",
    "    fig_h = fig_w / w * h\n",
    "    # plot the image\n",
    "    fig, ax = plt.subplots(figsize=(fig_h, fig_w))\n",
    "    \n",
    "    ax.imshow(data)\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        ax.text(x1, y1, label, color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the anchors\n",
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "# define the probability threshold for detected objects\n",
    "class_threshold = 0.6\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "    # decode the output of the network\n",
    "    boxes += utils.decode_netout(yhat[i][0], anchors[i], class_threshold, INPUT_H, INPUT_W)\n",
    "\n",
    "# correct the sizes of the bounding boxes for the shape of the image\n",
    "correct_yolo_boxes(boxes, image_h, image_w, INPUT_H, INPUT_W)\n",
    "\n",
    "# suppress non-maximal boxes\n",
    "utils.do_nms(boxes, 0.5)\n",
    "# get the details of the detected objects\n",
    "v_boxes, v_labels, v_scores = get_boxes(boxes, MSCOCO_LABELS, class_threshold)\n",
    "# summarize what we found\n",
    "for i in range(len(v_boxes)):\n",
    "    print(v_labels[i], v_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw what we found\n",
    "draw_boxes(photo_path, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
